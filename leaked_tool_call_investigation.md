# Claude Leaked Tool Call Investigation Report

> **Status**: ðŸ”„ In Progress - Log analysis complete, pending further verification
> **Last Updated**: 2026-02-04
> **Investigation Branch**: `investigation/leaked-tool-calls`

## Background

When using Claude models for tool calling, an issue was discovered: Claude sometimes "leaks" tool call information into text content instead of returning it through the proper `tool_calls` field. This causes tool calls to not be correctly identified and processed.

### Problem Symptoms

In Claude's response, the `tool_calls` field is empty, but the `content` field contains text in a format like:

```python
{'id': 'toolu_vrtx_01X1tcW6qR1uUoUkfpZMiXnH', 'input': {'ticker': 'MSFT'}, 'name': 'get_stock_price', 'type': 'tool_use'}
```

## Version Evolution

### 1. fix/neil-fixes Branch (Base Version)

Neil first implemented a simple and direct fix:

**Core Logic** ([`_process_anthropic_native()`](src/argoproxy/tool_calls/output_handle.py:322-422)):

```python
import ast
if not claude_tool_calls and "{'id': 'toolu_" in text_content:
    try:
        # Find balanced dictionary
        start_idx = text_content.find("{'id': 'toolu_")
        balance = 0
        end_idx = -1
        for i, char in enumerate(text_content[start_idx:], start=start_idx):
            if char == '{': balance += 1
            elif char == '}': balance -= 1
            if balance == 0:
                end_idx = i + 1
                break

        if end_idx != -1:
            leaked_str = text_content[start_idx:end_idx]
            logger.warning(f"Found leaked tool string: {leaked_str}")
            leaked_dict = ast.literal_eval(leaked_str)
            claude_tool_calls = [leaked_dict]
            # Remove from text
            text_content = text_content[:start_idx] + text_content[end_idx:]
    except Exception as e:
        logger.warning(f"Failed to parse leaked tool: {e}")
```

**Characteristics**:

- Simple and direct, fixes the problem when detected
- No configuration switch, always enabled
- No logging, no data collection
- Concise code, about 20 lines of core logic

### 2. master Branch (Enhanced Version)

Building on Neil's work, the master branch added the following features:

#### 2.1 Configuration Switch

```python
# config.py
_enable_leaked_tool_fix: bool = False

@property
def enable_leaked_tool_fix(self):
    """Check if leaked tool call fix is enabled."""
    return self._enable_leaked_tool_fix

# Environment variable support
if env_enable_leaked_tool_fix := os.getenv("ENABLE_LEAKED_TOOL_FIX"):
    config_data._enable_leaked_tool_fix = str_to_bool(env_enable_leaked_tool_fix)
```

**Design Intent**:

- Fix disabled by default, conservative strategy
- Can be enabled via configuration or environment variable
- Easy to control behavior in production environments

#### 2.2 Logging System

Added complete logging functionality for collecting and analyzing leak cases:

```python
def _log_leaked_tool_case(
    text_content: str,
    leaked_str: str,
    request_data: Optional[Dict[str, Any]] = None,
    response_data: Optional[Dict[str, Any]] = None,
) -> None:
    """Log a leaked tool call case for analysis."""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "leaked_tool_string": leaked_str,
        "full_text_content": text_content,
        "context_before": ...,
        "context_after": ...,
    }

    if request_data:
        log_entry["request"] = request_data
    if response_data:
        log_entry["response"] = response_data

    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(log_entry, f, indent=2, ensure_ascii=False)
```

**Design Intent**:

- Collect leak cases for analysis
- Record complete context (request, response, surrounding text)
- Auto-compress logs (when exceeding 50MB)
- Facilitate future improvements to fix logic

#### 2.3 Modified Processing Logic

```python
# Check if fix is enabled in config
config_data, _ = load_config(verbose=False)
enable_fix = config_data.enable_leaked_tool_fix if config_data else False

if not claude_tool_calls and "{'id': 'toolu_" in text_content:
    try:
        # ... find leaked tool call ...

        # Always log (even if enable_fix=False)
        _log_leaked_tool_case(
            text_content=text_content,
            leaked_str=leaked_str,
            request_data=request_data,
            response_data=response_data,
        )

        if enable_fix:
            # Parse and remove only when fix is enabled
            leaked_dict = ast.literal_eval(leaked_str)
            claude_tool_calls = [leaked_dict]
            text_content = text_content[:start_idx] + text_content[end_idx:]
        else:
            # Log only, don't fix
            logger.warning(f"[LEAKED TOOL FIX DISABLED] Found potential leaked tool call...")
    except Exception as e:
        logger.warning(f"Failed to process potential leaked tool: {e}")
```

## Issue Report

### Symptoms

- **Official OpenAI native mode**: Works normally
- **master branch (with leaked tool fix enabled)**: Shows `internal error, upstream error 500`
- **fix/neil-fixes branch**: No such error

### Root Cause Analysis

The logging functionality added in the master branch has multiple potential risk points:

#### 1. JSON Serialization Failure (Most Likely)

```python
if request_data:
    log_entry["request"] = request_data  # May contain non-serializable objects
if response_data:
    log_entry["response"] = response_data  # May contain non-serializable objects

json.dump(log_entry, f, indent=2, ensure_ascii=False)  # May fail
```

**Issues**:

- `request_data` or `response_data` may contain non-JSON-serializable objects
- Large object serialization may cause memory issues
- Special character encoding problems

#### 2. File System Operation Failure

```python
log_dir = _get_leaked_tool_log_dir()  # May fail
dir_size = _get_log_dir_size(log_dir)  # May fail
if dir_size > 50 * 1024 * 1024:
    _compress_log_files(log_dir)  # May fail and be time-consuming
```

**Issues**:

- Insufficient disk space
- Permission issues (cannot create directory or write files)
- Compression operation takes too long causing timeout

#### 3. Critical Issue: Logging Occurs Even When Fix is Disabled

```python
# Always log (even if enable_fix=False)
_log_leaked_tool_case(...)

if enable_fix:
    # Fix logic
else:
    # Log only, don't fix
```

This means logging is executed whenever a leaked tool call is detected, regardless of whether the fix feature is enabled.

## Code Comparison

| Feature | fix/neil-fixes | master |
| --- | --- | --- |
| Leak Detection | âœ… | âœ… |
| Auto Fix | âœ… Always enabled | âš™ï¸ Configurable |
| Logging | âŒ | âœ… |
| Log Compression | âŒ | âœ… |
| Config Switch | âŒ | âœ… |
| Lines of Code | ~20 | ~150 |
| Dependencies | ast | ast, gzip, datetime, Path, config |
| File I/O | âŒ | âœ… |
| Potential Risk Points | 1 (ast.literal_eval) | 5+ |

## Proposed Solutions

### Solution 1: Revert to fix/neil-fixes Simple Approach

**Pros**:

- Simple and reliable
- Better performance
- No side effects

**Cons**:

- Loses data collection capability

**Implementation**:

```bash
git checkout fix/neil-fixes -- src/argoproxy/tool_calls/output_handle.py
git checkout fix/neil-fixes -- src/argoproxy/config.py
```

### Solution 2: Fix master Branch Logging Issues

If data collection capability is needed, recommend:

#### 2.1 Use Safe JSON Serialization

```python
def _safe_serialize(obj):
    """Safe serialization, handle non-serializable objects"""
    try:
        return json.dumps(obj, default=str)
    except Exception:
        return str(obj)[:1000]  # Truncate

log_entry = {
    "timestamp": datetime.now().isoformat(),
    "leaked_tool_string": leaked_str,
    "text_preview": text_content[:500] if text_content else "",
    "text_length": len(text_content),
}

# Only log key information, not full request/response
if request_data:
    log_entry["request_model"] = request_data.get("model")
    log_entry["request_has_tools"] = "tools" in request_data
```

#### 2.2 Async Logging

```python
from concurrent.futures import ThreadPoolExecutor

_log_executor = ThreadPoolExecutor(max_workers=1)

def _log_leaked_tool_case_async(...):
    """Async logging, don't block main flow"""
    try:
        _log_executor.submit(_log_leaked_tool_case, ...)
    except Exception:
        pass  # Silent failure
```

#### 2.3 Add Switch to Control Logging

```python
# Only log when fix is enabled
if enable_fix:
    _log_leaked_tool_case(...)
    leaked_dict = ast.literal_eval(leaked_str)
    claude_tool_calls = [leaked_dict]
    text_content = text_content[:start_idx] + text_content[end_idx:]
```

### Solution 3: Hybrid Approach (Recommended)

1. **Keep simple fix logic** (from fix/neil-fixes)
2. **Add optional lightweight logging**:
   - Only enable when `DEBUG_LEAKED_TOOLS=true`
   - Only log key information (leaked string, timestamp, model name)
   - Use async writing
3. **Remove complex compression logic**

## Verification Steps

1. **Check logs**:

   ```bash
   grep "Failed to log leaked tool call case" /path/to/logs
   grep "Failed to compress" /path/to/logs
   ```

2. **Check disk and permissions**:

   ```bash
   ls -la /path/to/leaked_tool_calls/
   du -sh /path/to/leaked_tool_calls/
   ```

3. **Test fix/neil-fixes**:
   ```bash
   git checkout fix/neil-fixes
   # Run the same test cases
   ```

## New Finding: Upstream API 500 Error

### Problem Description

User reported:

- Direct use of `https://apps-dev.inside.anl.gov/argoapi/v1` works normally
- Using Claude-4.5-opus through argo-proxy (`http://0.0.0.0:60475/v1`) shows "Internal Server Error: Upstream API error: 500"
- Using Gemini models through argo-proxy works normally

### Error Source Analysis

The error message "Upstream API error: 500" comes from [`chat.py:608-616`](src/argoproxy/endpoints/chat.py:608-616):

```python
async with session.post(api_url, headers=headers, json=data) as upstream_resp:
    if upstream_resp.status != 200:
        error_text = await upstream_resp.text()
        return web.json_response(
            {"error": f"Upstream API error: {upstream_resp.status} {error_text}"},
            status=upstream_resp.status,
            content_type="application/json",
        )
```

This indicates **the upstream ARGO API itself returned a 500 error**, not an error generated internally by argo-proxy.

### Possible Causes

#### 1. Request Data Transformation Issues

argo-proxy transforms data before sending requests, which may cause the upstream API to fail:

- **Tool call format conversion**: [`handle_tools()`](src/argoproxy/tool_calls/input_handle.py) may produce incompatible formats
- **Message format processing**: [`scrutinize_message_entries()`](src/argoproxy/utils/input_handle.py) may modify message structure
- **Model name mapping**: Model names may be incorrectly mapped

#### 2. Claude-Specific Request Format Issues

Claude models may have special requirements for request format:

- System message handling
- Tool definition format
- Message role ordering

#### 3. Logging Side Effects (Unlikely)

Although logging occurs during **response processing**, if there are any side effects during request preparation, it may affect request data.

### Debugging Recommendations

#### 1. Compare Request Data

There's already log output at [`chat.py:722-724`](src/argoproxy/endpoints/chat.py:722-724):

```python
logger.warning(
    f"[chat] data: {json.dumps(sanitize_data_for_logging(data), indent=4)}"
)
```

Check the actual request data sent to the upstream API.

#### 2. Check Upstream Error Details

The `error_text` in the error message should contain detailed error information returned by the upstream API. Need to check complete logs.

#### 3. Test Upstream API Directly

Use the same request data to call the upstream API directly to confirm if it's a data format issue:

```bash
curl -X POST https://apps-dev.inside.anl.gov/argoapi/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "claude-4.5-opus", "messages": [...], "tools": [...]}'
```

#### 4. Compare Request Processing Between Branches

Although `input_handle.py` has no differences, other changes in the master branch may indirectly affect request processing.

### Key Differences Summary

| Component | fix/neil-fixes | master |
| --- | --- | --- |
| Version | 2.8.0 | 2.8.1 |
| usage.py | Does not exist | New |
| Logging | None | Yes |
| Config Switch | None | Yes |
| Response Processing | Simple | Complex |

## Conclusion

### Original Issue (Potential Problems from Logging)

The logging functionality added in the master branch on top of fix/neil-fixes introduced multiple potential failure points. The most likely cause is JSON serialization failure or file system operation issues.

### New Issue (Upstream API 500 Error)

The upstream ARGO API returns a 500 error, requiring further investigation:

1. Check request data sent to upstream
2. View detailed error information returned by upstream
3. Confirm if it's a Claude-specific format issue

**Recommended Actions**:

1. **Immediate**: View complete error logs to get detailed error information from upstream API
2. **Short-term**: Revert to fix/neil-fixes simple approach to confirm if it resolves the issue
3. **Long-term**: If data collection is needed, implement lightweight async logging solution

---

## TODO

- [ ] Wait for colleague to send complete error logs
- [ ] Analyze detailed error information returned by upstream API
- [ ] Compare request data sent by master and fix/neil-fixes
- [ ] Confirm root cause
- [ ] Develop fix plan

---

## Log Analysis Section

### Received Log Files

**Source**: `reference/bugs_report/leaked_tool_logs_20260128_171914.tar.gz`

**Extracted Location**: `reference/bugs_report/leaked_tool_logs/`

**File List**:
- `leaked_tool_20260128_171422_165810.json` (83,269 bytes)
- `leaked_tool_20260128_171653_513513.json` (89,432 bytes)

---

### Log 1: leaked_tool_20260128_171422_165810.json

**Timestamp**: 2026-01-28T17:14:22.166209

**Leaked Tool Call**:
```python
{
    'id': 'toolu_vrtx_01HxkqNiX9NvAXS6Aejq6Wph',
    'input': {
        'command': 'gh api repos/AD-SDL/MADSci/issues/218/sub_issues 2>/dev/null || gh api graphql -f query=\'...\' 2>/dev/null || echo "Sub-issues API not available"',
        'description': 'Try sub_issues API endpoint'
    },
    'name': 'bash',
    'type': 'tool_use',
    'cache_control': None
}
```

**Context**:
- **context_before**: "Let me check the GitHub sub-issues feature more directly - it looks like they might be using a newer GitHub feature:"
- **context_after**: "" (empty)

**Request Information**:
| Field | Value |
|-------|-------|
| model | `claudeopus45` |
| max_tokens | 20999 |
| stream | false |
| user | luckierdodge |

**Client**: OpenCode (CLI coding assistant)

**Response Structure**:
```json
{
  "content": "Let me check the GitHub sub-issues feature more directly - it looks like they might be using a newer GitHub feature:{'id': 'toolu_vrtx_01HxkqNiX9NvAXS6Aejq6Wph', ...}",
  "tool_calls": []
}
```

---

### Log 2: leaked_tool_20260128_171653_513513.json

**Timestamp**: 2026-01-28T17:16:53.513590

**Leaked Tool Call**:
```python
{
    'id': 'toolu_vrtx_01DJaLx1tDTwxMoxLhcBqnMj',
    'input': {
        'description': 'Explore EventClient/EventManager',
        'prompt': 'Explore the EventClient and EventManager implementation in this codebase...',
        'subagent_type': 'explore'
    },
    'name': 'task',
    'type': 'tool_use',
    'cache_control': None
}
```

**Context**:
- **context_before**: "Now let me explore the current EventClient and EventManager codebase to understand the existing implementation:"
- **context_after**: "" (empty)

**Request Information**:
| Field | Value |
|-------|-------|
| model | `claudeopus45` |
| max_tokens | 20999 |
| stream | false |
| user | luckierdodge |

**Client**: OpenCode (CLI coding assistant)

**Response Structure**:
```json
{
  "content": "Now let me explore the current EventClient and EventManager codebase to understand the existing implementation:{'id': 'toolu_vrtx_01DJaLx1tDTwxMoxLhcBqnMj', ...}",
  "tool_calls": []
}
```

---

### Version and Code Correlation Analysis

#### argo-proxy Version Used

The logs were generated by argo-proxy's [`_log_leaked_tool_case()`](src/argoproxy/tool_calls/output_handle.py:109-167) function.

**Log Format Verification**:

| Log Field | Code Location | Match |
|-----------|---------------|-------|
| `timestamp` | Line 142 | âœ“ |
| `leaked_tool_string` | Line 143 | âœ“ |
| `full_text_content` | Line 144 | âœ“ |
| `context_before` | Lines 145-147 | âœ“ |
| `context_after` | Lines 148-152 | âœ“ |
| `request` | Lines 155-156 | âœ“ |
| `response` | Lines 157-158 | âœ“ |

**Filename Format**: `leaked_tool_{timestamp}.json` (Line 139)

**Conclusion**: Logs were generated by **master branch** (version 2.8.1+) because:
1. Logging functionality is new in master branch
2. fix/neil-fixes branch (2.8.0) does not have logging functionality

#### Important Finding: Abnormal Request Format

The tool definitions in the logs use **Anthropic native format**:

```json
{
  "input_schema": {
    "type": "object",
    "properties": {...}
  },
  "name": "bash",
  "cache_control": null,
  "description": "...",
  "type": "custom"
}
```

Instead of OpenAI format (the input format argo-proxy expects):

```json
{
  "type": "function",
  "function": {
    "name": "bash",
    "parameters": {...}
  }
}
```

**This means**:
1. The client (OpenCode) directly sends Anthropic format tool definitions
2. The request may bypass argo-proxy's tool format conversion logic
3. Or argo-proxy's input handling doesn't correctly convert this format

---

### Key Findings

#### 1. Model Information
- Both cases use **`claudeopus45`** model (Claude 4.5 Opus)
- This is Anthropic's latest model

#### 2. Leak Pattern Characteristics

| Characteristic | Description |
|----------------|-------------|
| Format | Python dict format (not JSON) |
| ID Prefix | `toolu_vrtx_` (Anthropic native format) |
| Position | Immediately follows explanatory text, no separator |
| cache_control | Contains `None` value (Python-specific) |

#### 3. Abnormal Response Structure

```
Normal case:
  response.content = "text content"
  response.tool_calls = [{"id": "...", "function": {...}}]

Leak case:
  response.content = "text content{'id': 'toolu_vrtx_...', ...}"
  response.tool_calls = []
```

#### 4. Tool Definition Format

Tools in the request use **Anthropic native format**:
```json
{
  "input_schema": {
    "type": "object",
    "properties": {...}
  },
  "name": "bash",
  "cache_control": null,
  "description": "...",
  "type": "custom"
}
```

Instead of OpenAI format:
```json
{
  "type": "function",
  "function": {
    "name": "bash",
    "parameters": {...}
  }
}
```

#### 5. Client Information

- **Client**: OpenCode (https://github.com/anomalyco/opencode)
- **Type**: CLI coding assistant
- **User**: luckierdodge
- **Working Directory**: /Users/luckierdodge/AD-SDL/MADSci

---

### Root Cause Analysis

Based on log analysis, the root cause may be:

#### Hypothesis 1: Upstream ARGO API Response Format Issue â­ Most Likely

Claude model's `tool_use` blocks are not correctly parsed into structured `tool_calls`, but are serialized as Python dict format and embedded in text content.

**Evidence**:
- Leaked format is Python dict (uses single quotes, `None` instead of `null`)
- This indicates some code used `str()` or `repr()` instead of `json.dumps()`
- Upstream ARGO API may have a bug when processing Claude 4.5 Opus responses

**Code Correlation**:
- [`_process_anthropic_native()`](src/argoproxy/tool_calls/output_handle.py:342-464) expects response format:
  ```json
  {
    "response": {
      "content": "text",
      "tool_calls": [{"id": "toolu_...", "input": {...}, "name": "...", "type": "tool_use"}]
    }
  }
  ```
- But actually receives `tool_calls: []` with tool calls embedded in `content`

#### Hypothesis 2: Model Behavior Anomaly

Claude 4.5 Opus may "leak" tool calls into text output in certain situations instead of returning them through the normal tool call mechanism.

**Evidence**:
- Both cases occurred with Claude 4.5 Opus
- Tool calls immediately follow explanatory text without line breaks or separators

#### Hypothesis 3: Request Format Incompatibility

The tool definition format sent by OpenCode client may not be fully compatible with what the upstream API expects.

**Evidence**:
- Tool definitions use `type: "custom"` field (non-standard)
- Contains `cache_control` field (Anthropic-specific)
- Tool format is Anthropic native format, not OpenAI format

**Code Correlation**:
- argo-proxy's [`handle_tools_native()`](src/argoproxy/tool_calls/input_handle.py:247-475) handles tool format conversion
- If input is already in Anthropic format, conversion logic may not handle it correctly

---

### Correlation with Existing Fixes

| Branch | Handling Method |
|--------|-----------------|
| fix/neil-fixes | Detect `{'id': 'toolu_` pattern and parse to fix |
| master | Add logging + optional fix |

**Neil's fix logic** can correctly handle this situation:
```python
if not claude_tool_calls and "{'id': 'toolu_" in text_content:
    # Find and parse leaked tool call
    leaked_dict = ast.literal_eval(leaked_str)
    claude_tool_calls = [leaked_dict]
```

---

### Next Steps

1. **Confirm Fix Effectiveness**
   - [ ] Test the same request on fix/neil-fixes branch
   - [ ] Verify tool calls are correctly extracted

2. **Investigate Upstream API**
   - [ ] Check ARGO API support for Claude 4.5 Opus
   - [ ] Confirm if this is a known issue
   - [ ] Contact upstream team to report this issue

3. **Optimize Fix Solution**
   - [ ] Consider adding handling for `cache_control: None`
   - [ ] Ensure fix logic can handle multiple consecutive tool calls
   - [ ] Add compatibility handling for Anthropic native tool format input

4. **Long-term Solution**
   - [ ] Report this issue to upstream
   - [ ] Consider adding more robust tool call parsing logic
   - [ ] Evaluate whether to support direct passthrough of Anthropic native format

---

## Code Reference

### Key Files

| File | Function |
|------|----------|
| [`output_handle.py`](src/argoproxy/tool_calls/output_handle.py) | Response processing and leak detection |
| [`input_handle.py`](src/argoproxy/tool_calls/input_handle.py) | Request tool format conversion |
| [`config.py`](src/argoproxy/config.py) | Configuration management (`enable_leaked_tool_fix`) |

### Leak Detection Logic

```python
# output_handle.py:400-445
if not claude_tool_calls and "{'id': 'toolu_" in text_content:
    # Find balanced dictionary
    start_idx = text_content.find("{'id': 'toolu_")
    # ... balanced bracket finding ...
    
    if end_idx != -1:
        leaked_str = text_content[start_idx:end_idx]
        
        # Always log
        _log_leaked_tool_case(...)
        
        if enable_fix:
            # Parse and fix
            leaked_dict = ast.literal_eval(leaked_str)
            claude_tool_calls = [leaked_dict]
            text_content = text_content[:start_idx] + text_content[end_idx:]
```

### Version Information

| Branch | Version | Leak Fix | Logging |
|--------|---------|----------|---------|
| fix/neil-fixes | 2.8.0 | âœ… Always enabled | âŒ |
| master | 2.8.1+ | âš™ï¸ Configurable | âœ… |
| Current | 2.8.2 | âš™ï¸ Configurable | âœ… |

---

## Request Processing Flow Analysis

### Request Processing Chain

```
Client Request â†’ argo-proxy â†’ Upstream ARGO API â†’ Claude Model
```

### Key Processing Steps

1. **Receive Request** ([`chat.py:694`](src/argoproxy/endpoints/chat.py:694))
   ```python
   data = await request.json()
   ```

2. **Image Processing** ([`chat.py:712`](src/argoproxy/endpoints/chat.py:712))
   ```python
   data = await process_chat_images(session, data, config)
   ```

3. **Request Data Preparation** ([`chat.py:715-717`](src/argoproxy/endpoints/chat.py:715-717))
   ```python
   data = prepare_chat_request_data(
       data, config, model_registry, enable_tools=True
   )
   ```

4. **Tool Call Processing** ([`input_handle.py:483-528`](src/argoproxy/tool_calls/input_handle.py:483-528))
   - Detect model type: `determine_model_family(data.get("model", "gpt4o"))`
   - Claude model â†’ `model_type = "anthropic"`
   - Convert tool format: OpenAI â†’ Anthropic

5. **Send Request** ([`chat.py:607`](src/argoproxy/endpoints/chat.py:607))
   ```python
   async with session.post(api_url, headers=headers, json=data) as upstream_resp:
   ```

### Claude-Specific Format Conversion

When Claude model is detected, [`handle_tools_native()`](src/argoproxy/tool_calls/input_handle.py:247-475) performs the following conversions:

#### 1. Tool Definition Conversion
```python
# OpenAI format
{"type": "function", "function": {"name": "...", "parameters": {...}}}

# Converted to Anthropic format
{"name": "...", "input_schema": {...}}
```

#### 2. Tool Call Message Conversion
```python
# OpenAI format (assistant message with tool_calls)
{"role": "assistant", "tool_calls": [{"id": "...", "function": {...}}]}

# Converted to Anthropic format (content array with tool_use blocks)
{"role": "assistant", "content": [{"type": "tool_use", "id": "...", "name": "...", "input": {...}}]}
```

#### 3. Tool Result Message Conversion
```python
# OpenAI format
{"role": "tool", "tool_call_id": "...", "content": "..."}

# Converted to Anthropic format
{"role": "user", "content": [{"type": "tool_result", "tool_use_id": "...", "content": "..."}]}
```

### Potential Problem Points

1. **Format Conversion Errors**
   - Tool definition conversion may lose required fields
   - Message format conversion may be incomplete

2. **Upstream API Incompatibility**
   - Upstream ARGO API may expect specific format
   - Converted format may not be accepted

3. **Differences Between Branches**
   - Although `input_handle.py` has no differences
   - Other changes in master branch may indirectly affect request processing

### Verification Methods

1. **Compare Request Data**
   - Run the same request on both branches
   - Compare `[chat] data:` log output

2. **Test Upstream API Directly**
   - Use argo-proxy converted data to call upstream API directly
   - Confirm if it's a format issue

3. **Check Tool Conversion Logs**
   - View logs starting with `[Input Handle]`
   - Confirm tool format conversion is correct

---

## OpenCode Client Analysis

### Client Information

| Property | Value |
|----------|-------|
| Name | OpenCode |
| Repository | https://github.com/anomalyco/opencode |
| Version | v1.1.51 |
| Type | CLI coding assistant |
| Local Code | `reference/opencode/` |

### Tech Stack

OpenCode uses **Vercel AI SDK** (`@ai-sdk/*`) to handle different LLM providers:

```typescript
// provider.ts - Supported SDK packages
import { createAnthropic } from "@ai-sdk/anthropic"
import { createOpenAI } from "@ai-sdk/openai"
import { createGoogleGenerativeAI } from "@ai-sdk/google"
// ... more providers
```

### Anthropic Special Handling

OpenCode has special configuration for Anthropic/Claude models:

```typescript
// provider.ts:91-99
async anthropic() {
  return {
    autoload: false,
    options: {
      headers: {
        "anthropic-beta":
          "claude-code-20250219,interleaved-thinking-2025-05-14,fine-grained-tool-streaming-2025-05-14",
      },
    },
  }
}
```

### Tool Call ID Normalization

OpenCode normalizes Claude's `toolCallId`:

```typescript
// transform.ts:71-86
if (model.api.id.includes("claude")) {
  return msgs.map((msg) => {
    if ((msg.role === "assistant" || msg.role === "tool") && Array.isArray(msg.content)) {
      msg.content = msg.content.map((part) => {
        if ((part.type === "tool-call" || part.type === "tool-result") && "toolCallId" in part) {
          return {
            ...part,
            // Keep only alphanumeric and _-
            toolCallId: part.toolCallId.replace(/[^a-zA-Z0-9_-]/g, "_"),
          }
        }
        return part
      })
    }
    return msg
  })
}
```

### Key Findings

1. **Tool Format**: OpenCode uses AI SDK's standard format, tool calls are handled through `tool-call` and `tool-result` types

2. **Format Anomaly in Logs**: The tool format seen in logs is **Anthropic native API format**:
   ```python
   {'id': 'toolu_vrtx_01HxkqNiX9NvAXS6Aejq6Wph', 'input': {...}, 'name': 'bash', 'type': 'tool_use', 'cache_control': None}
   ```
   Not AI SDK format, indicating the problem occurs at the **upstream ARGO API** level

3. **Python Dict Format**: Leaked tool calls use Python dict format (single quotes, `None`), not JSON format (double quotes, `null`), indicating some code used `str()` or `repr()` instead of `json.dumps()`

---

## Related Case: LangChain Leak Issue

### Background

A colleague also encountered similar tool call leak issues when using LangChain.

### Common Characteristics

| Characteristic | OpenCode Case | LangChain Case |
|----------------|---------------|----------------|
| Model | Claude 4.5 Opus | Claude series |
| Leak Format | Python dict | To be confirmed |
| tool_calls Field | Empty array | To be confirmed |
| Upstream API | ARGO API | ARGO API |

### Inference

The common points of these two cases suggest the problem may be in:

1. **Upstream ARGO API** handling of Claude model responses
2. Claude model's special behavior in certain situations
3. Bug in tool call format conversion process

---

## Request Field Format in Logs

### Question

Is the `request` field in the logs already converted to ARGO gateway API format, or is it the raw request as received?

### Answer

**The `request` in logs is the converted ARGO gateway API format**, not the original request.

### Code Trace

1. **Receive Request** ([`chat.py:787`](src/argoproxy/endpoints/chat.py:787))
   ```python
   data = await request.json()  # Original request
   ```

2. **Request Conversion** ([`chat.py:807-809`](src/argoproxy/endpoints/chat.py:807-809))
   ```python
   # Prepare the request data (includes message scrutinization and normalization)
   data = prepare_chat_request_data(
       data, config, model_registry, enable_tools=True
   )
   ```

3. **Pass to ToolInterceptor** ([`chat.py:336-340`](src/argoproxy/endpoints/chat.py:336-340))
   ```python
   tool_calls, clean_text = cs.process(
       response_content,
       determine_model_family(data["model"]),
       request_data=data,  # <-- Converted data is passed
   )
   ```

4. **Log to File** ([`output_handle.py:419-424`](src/argoproxy/tool_calls/output_handle.py:419-424))
   ```python
   _log_leaked_tool_case(
       text_content=text_content,
       leaked_str=leaked_str,
       request_data=request_data,  # <-- This is converted data
       response_data=response_data,
   )
   ```

### Conversion Process

The `prepare_chat_request_data()` function performs the following conversions:

1. **User Info Replacement**: `data["user"] = config.user`
2. **Model Name Mapping**: `model_registry.resolve_model_name()`
3. **Message Format Normalization**: `scrutinize_message_entries()`
4. **Tool Format Conversion**: `handle_tools()` - Convert OpenAI format to target model format

### Evidence in Logs

From the log files, we can see tool definitions use **Anthropic native format**:

```json
{
  "input_schema": {
    "type": "object",
    "properties": {...}
  },
  "name": "bash",
  "cache_control": null,
  "description": "...",
  "type": "custom"
}
```

This indicates:
1. Tool format has been converted from OpenAI format to Anthropic format
2. Or the client (OpenCode) directly sent Anthropic format, and argo-proxy didn't convert

### Impact

Since logs record the converted request, we cannot directly see the original request format from the client. If debugging the original request is needed:

1. Add logging before `prepare_chat_request_data()`
2. Or use the output from `log_original_request()` (line 798)

---

## Comprehensive Conclusion

### Root Cause (Ranked by Likelihood)

1. **Upstream ARGO API Response Processing Bug** â­â­â­
   - Claude's `tool_use` blocks are not correctly parsed
   - Serialized as Python dict format embedded in text content
   - Evidence: Leaked format is Python dict (single quotes, `None`)

2. **Claude 4.5 Opus Model Behavior Anomaly** â­â­
   - Model "leaks" tool calls into text output in certain situations
   - May be related to specific prompts or tool definition formats

3. **Request Format Incompatibility** â­
   - OpenCode sends Anthropic native format tool definitions
   - May not be fully compatible with what upstream API expects

### Fix Solution Evaluation

| Solution | Pros | Cons | Recommendation |
|----------|------|------|----------------|
| fix/neil-fixes Simple Fix | Simple, reliable, no side effects | No data collection | â­â­â­â­â­ |
| master Branch Logging | Can collect data for analysis | Complex, has potential risks | â­â­â­ |
| Report to Upstream | Root cause fix | Depends on upstream response | â­â­â­â­ |

### Recommended Actions

1. **Immediate**: Enable `ENABLE_LEAKED_TOOL_FIX=true` or use fix/neil-fixes branch
2. **Short-term**: Report this issue to upstream ARGO API team
3. **Long-term**: Optimize logging functionality with async writing and safe serialization